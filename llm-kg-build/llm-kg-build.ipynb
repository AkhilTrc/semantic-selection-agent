{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4b0bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.13.2' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install -U langchain-community\n",
    "!pip install unstructured\n",
    "!pip install libmagic\n",
    "!pip install unstructured[pdf]\n",
    "!pip install yachalk\n",
    "!pip install seaborn\n",
    "!pip install pyvis\n",
    "!pip isntall networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c4c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'semantic-selection-agent (3.9.18) (Python 3.9.18)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/RISHI R/semantic-selection-agent/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3e154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.makedirs('./docs', exist_ok=True)\n",
    "from pyvis.network import Network\n",
    "graph_output_directory = \"./docs/index_LA.html\"\n",
    "\n",
    "LOG_FILE = './processed_files.log'\n",
    "\n",
    "import networkx as nx\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader, TextLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "palette = \"hls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c943c378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    # Use this cell only if Chunking text\\n\\nsplitter = RecursiveCharacterTextSplitter(\\n    chunk_size=1500,\\n    chunk_overlap=150,\\n    length_function=len,\\n    is_separator_regex=False,\\n)\\n\\npages = splitter.split_documents(documents)\\nprint(\"Number of chunks = \", len(pages))\\nprint(pages[5].page_content)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    # Use this cell only if Chunking text\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n",
    "print(pages[5].page_content)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ef57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     Process to automate finding and incorporating new .txt files from a directory\\n\\nGRAPH_CSV_PATH = outputdirectory / \"graph.csv\"\\nCHUNKS_CSV_PATH = outputdirectory / \"chunks.csv\"\\nPROCESSED_LOG_PATH = \"processed_files.log\"\\n\\n## --- State Management: Identify New Files ---\\n\\n# Read the list of already processed files\\ntry:\\n    with open(PROCESSED_LOG_PATH, \\'r\\') as f:\\n        processed_files = set(f.read().splitlines())\\nexcept FileNotFoundError:\\n    processed_files = set()\\n\\n# Get the list of all current .txt files in the directory\\ncurrent_files = {str(p) for p in inputdirectory.glob(\"**/*.txt\")}\\n\\n# Determine which files are new\\nnew_files_to_process = list(current_files - processed_files)\\n\\nprint(f\"Found {len(new_files_to_process)} new file(s) to process.\")\\nprint(new_files_to_process)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"     Process to automate finding and incorporating new .txt files from a directory\n",
    "\n",
    "GRAPH_CSV_PATH = outputdirectory / \"graph.csv\"\n",
    "CHUNKS_CSV_PATH = outputdirectory / \"chunks.csv\"\n",
    "PROCESSED_LOG_PATH = \"processed_files.log\"\n",
    "\n",
    "## --- State Management: Identify New Files ---\n",
    "\n",
    "# Read the list of already processed files\n",
    "try:\n",
    "    with open(PROCESSED_LOG_PATH, 'r') as f:\n",
    "        processed_files = set(f.read().splitlines())\n",
    "except FileNotFoundError:\n",
    "    processed_files = set()\n",
    "\n",
    "# Get the list of all current .txt files in the directory\n",
    "current_files = {str(p) for p in inputdirectory.glob(\"**/*.txt\")}\n",
    "\n",
    "# Determine which files are new\n",
    "new_files_to_process = list(current_files - processed_files)\n",
    "\n",
    "print(f\"Found {len(new_files_to_process)} new file(s) to process.\")\n",
    "print(new_files_to_process)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d88ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Set\n",
    "import openai\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "MODEL_NAME = 'gpt-4.1-nano'\n",
    "\n",
    "class PromptEngine:\n",
    "    def __init__(self):\n",
    "        self.cache: Dict[Tuple[str, str], str] = {}\n",
    "\n",
    "    def build(self, pairs: List[Tuple[str, str]]) -> List[Tuple[Tuple[str, str], str]]:\n",
    "        prompts = []\n",
    "        for e1, e2 in pairs:\n",
    "            if (e1, e2) not in self.cache:\n",
    "                prompt = f\"\"\"\n",
    "                You are a creative alchemist. Your job is to invent new elements by combining two existing ones in imaginative yet plausible ways.\n",
    "\n",
    "                When given two elements, combine their characteristics to create a new, unique element.\n",
    "                Express each result as:\n",
    "                `[Element1] and [Element2] gives me [ResultElement]`\n",
    "\n",
    "                **Rules:**\n",
    "\n",
    "                1. For each new element generated, attempt to combine it with each of the original input elements (the base set), but **do not** combine new elements with each other unless one is from the base set.\n",
    "                2. Continue this process for several generations, always only pairing a newly created element with any element from the original base set.\n",
    "                3. Each combination should produce a plausible new element, grounded in the properties or concepts of the ingredients.\n",
    "                4. Do not repeat combinations or reverse orderings (e.g., if \"Water and Fire\" is done, skip \"Fire and Water\").\n",
    "\n",
    "                **Template for output:**\n",
    "\n",
    "                ```\n",
    "                [Element1] and [Element2] gives me [ResultElement]\n",
    "                ```\n",
    "\n",
    "                **Input Elements:**\n",
    "\n",
    "                * {e1}\n",
    "                * {e2}\n",
    "\n",
    "                **Step-by-step:**\n",
    "\n",
    "                1. Combine {e1} and {e2} to create [O1].\n",
    "                2. Combine [O1] with {e1} (if not already used).\n",
    "                3. Combine [O1] with {e2} (if not already used).\n",
    "                4. For each new element produced, only combine with the original input elements, not with other new elements.\n",
    "\n",
    "                ---\n",
    "\n",
    "                **Example Workflow:**\n",
    "                Suppose Input Elements: **Fire** and **Water**\n",
    "\n",
    "                ```\n",
    "                Fire and Water gives me Steam\n",
    "                Steam and Fire gives me Energy\n",
    "                Steam and Water gives me Cloud\n",
    "                ```\n",
    "             \"\"\"\n",
    "                prompts.append(((e1, e2), prompt))\n",
    "        return prompts\n",
    "\n",
    "    def cache_result(self, pair: Tuple[str, str], result: str):\n",
    "        self.cache[pair] = result\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, model: str = MODEL_NAME):\n",
    "        self.model = model\n",
    "\n",
    "    def batch_query(self, prompts: List[str]) -> List[str]:\n",
    "        responses = []\n",
    "        for prompt in prompts:\n",
    "            resp = openai.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            text = resp.choices[0].message.content.strip()\n",
    "            responses.append(text)\n",
    "        return responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05eafa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def text2Dataframe(text_chunks) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for chunk in text_chunks:\n",
    "        row = {\n",
    "            \"text\": chunk.page_content,\n",
    "            **chunk.metadata,\n",
    "            \"chunk_id\": uuid.uuid4().hex,\n",
    "        }\n",
    "        rows = rows + [row]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e0032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "def generate(model, system, user):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def graphPrompt(input: str, metadata={}, model=\"gpt-4.1-mini\"):\n",
    "    if model == None:\n",
    "        model = \"gpt-4.1-mini\"\n",
    "\n",
    "    # model_info = client.show(model_name=model)\n",
    "    # print( chalk.blue(model_info))\n",
    "\n",
    "    SYS_PROMPT = (\n",
    "        \"You are a network graph maker who extracts terms and their relations from a given context. \"\n",
    "        \"You are provided with a context text chunk (delimited by ```) Your task is to extract the ontology \"\n",
    "        \"of terms mentioned in the given context. These terms should represent the key concepts as per the context. \\n\"\n",
    "        \"Thought 1: While traversing through each sentence, Think about the key terms mentioned in it.\\n\"\n",
    "            \"\\tTerms may include object, entity, location, organization, person, \\n\"\n",
    "            \"\\tcondition, acronym, documents, service, concept, etc.\\n\"\n",
    "            \"\\tTerms should be as atomistic as possible\\n\\n\"\n",
    "        \"Thought 2: Think about how these terms can have one on one relation with other terms.\\n\"\n",
    "            \"\\tTerms can be related to many other terms\\n\\n\"\n",
    "        \"Thought 3: Find out the relation between each such related pair of terms. \\n\\n\"\n",
    "        \"Format your output as a list of json. Each element of the list contains a pair of terms\"\n",
    "        \"and the relation between them, like the following: \\n\"\n",
    "        \"[\\n\"\n",
    "        \"   {\\n\"\n",
    "        '       \"node_1\": \"A concept from extracted ontology\",\\n'\n",
    "        '       \"node_2\": \"A related concept from extracted ontology\",\\n'\n",
    "        '       \"edge\": \"relationship between the two concepts, node_1 and node_2 in one or two sentences\"\\n'\n",
    "        \"   }, {...}\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "\n",
    "    USER_PROMPT = f\"context: ```{input}``` \\n\\n output: \"\n",
    "    response = generate(model=model, system=SYS_PROMPT, user=USER_PROMPT)\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "        result = [dict(item, **metadata) for item in result]\n",
    "    except:\n",
    "        print(\"\\n\\nERROR ### Here is the buggy response: \", response, \"\\n\\n\")\n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4d643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "def df2Graph(dataframe: pd.DataFrame, model=None) -> list:\n",
    "    # dataframe.reset_index(inplace=True)\n",
    "    results = dataframe.apply(\n",
    "        lambda row: graphPrompt(row.text, {\"chunk_id\": row.chunk_id}, model), axis=1\n",
    "    )\n",
    "    # invalid json results in NaN\n",
    "    results = results.dropna()\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities.\n",
    "    concept_list = np.concatenate(results).ravel().tolist()\n",
    "    return concept_list\n",
    "\n",
    "def graph2Df(nodes_list) -> pd.DataFrame:\n",
    "    ## Remove all NaN entities\n",
    "    graph_dataframe = pd.DataFrame(nodes_list).replace(\" \", np.nan)\n",
    "    graph_dataframe = graph_dataframe.dropna(subset=[\"node_1\", \"node_2\"])\n",
    "    graph_dataframe[\"node_1\"] = graph_dataframe[\"node_1\"].apply(lambda x: x.lower())\n",
    "    graph_dataframe[\"node_2\"] = graph_dataframe[\"node_2\"].apply(lambda x: x.lower())\n",
    "\n",
    "    return graph_dataframe\n",
    "\n",
    "def display_graph(G):\n",
    "    ## Display & Save Graph Visualization\n",
    "    #\n",
    "    net = Network(\n",
    "        notebook=False,\n",
    "        # bgcolor=\"#1a1a1a\",\n",
    "        cdn_resources=\"remote\",\n",
    "        height=\"900px\",\n",
    "        width=\"100%\",\n",
    "        select_menu=True,\n",
    "        # font_color=\"#cccccc\",\n",
    "        filter_menu=False,\n",
    "    )\n",
    "\n",
    "    net.from_nx(G)\n",
    "    # net.repulsion(node_distance=150, spring_length=400)\n",
    "    net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "    # net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "    net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "    net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1127d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a717f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_viz_builder(dfg):\n",
    "    nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node in nodes:\n",
    "        G.add_node(\n",
    "            str(node)\n",
    "        )\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for index, row in dfg.iterrows():\n",
    "        G.add_edge(\n",
    "            str(row[\"node_1\"]),\n",
    "            str(row[\"node_2\"]),\n",
    "            title=row[\"edge\"],\n",
    "            weight=row['count']/4\n",
    "        )\n",
    "\n",
    "    \"\"\"     Girvan Newman Algorithm & Community coloring / Can also be used for Stopping Condition\n",
    "\n",
    "    # Graph Communities & Coloring\n",
    "    communities_generator = nx.community.girvan_newman(G)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    communities = sorted(map(sorted, next_level_communities))\n",
    "    print(\"Number of Communities = \", len(communities))\n",
    "    print(communities)\n",
    "    df_colors = colors2Community(communities)\n",
    "\n",
    "    for index, row in df_colors.iterrows():\n",
    "        G.nodes[row['node']]['group'] = row['group']\n",
    "        G.nodes[row['node']]['color'] = row['color']\n",
    "        G.nodes[row['node']]['size'] = G.degree[row['node']]\"\n",
    "    \"\"\"\n",
    "\n",
    "    display_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02c1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "        self.prompt_engine = PromptEngine()\n",
    "        self.llm = LLMClient()\n",
    "        self.seen_nodes: Set[str] = set()\n",
    "\n",
    "    def get_unexplored_nodes(self) -> List[str]:\n",
    "        return [n for n in self.graph.nodes() if n not in self.seen_nodes]\n",
    "\n",
    "    def run_loop(\n",
    "        self,\n",
    "        base_elements: List[str],\n",
    "        max_iters: int = 5,\n",
    "        batch_size: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.base = [e.lower() for e in base_elements]\n",
    "        for node in self.base:\n",
    "            self.graph.add_node(node)\n",
    "        print(f\"Seeded graph with base elements: {base_elements}\")\n",
    "\n",
    "        for iteration in range(1, max_iters + 1):\n",
    "            to_explore = self.get_unexplored_nodes()[:batch_size]\n",
    "            if not to_explore:\n",
    "                print(\"No more new nodes — stopping early.\")\n",
    "                break\n",
    "\n",
    "            print(f\"\\n--- Iteration {iteration}: exploring {to_explore} ---\")\n",
    "\n",
    "            pairs = [(new, base) \n",
    "                     for new in to_explore \n",
    "                     for base in self.base \n",
    "                     if new != base]\n",
    "\n",
    "            built = self.prompt_engine.build(pairs)\n",
    "            pairs_batch, prompts = zip(*built)\n",
    "            responses = self.llm.batch_query(list(prompts))\n",
    "\n",
    "            for (node, _), raw in zip(pairs_batch, responses):\n",
    "                print(f\"\\n🔄 Response for '{node}':\\n{raw}\")\n",
    "                try:\n",
    "                    triples = self.preprocess_response(raw)\n",
    "                    text_chunks = raw.split('\\n')\n",
    "                    text_chunks = [chunk.strip() for chunk in text_chunks if chunk.strip()]\n",
    "                    df = text2Dataframe(text_chunks)\n",
    "                    concepts_list = df2Graph(df, model='gpt-4.1-mini')\n",
    "                    dfg1 = graph2Df(concepts_list)\n",
    "                    if not os.path.exists(outputdirectory):\n",
    "                        os.makedirs(outputdirectory)\n",
    "                    \n",
    "                    dfg1.to_csv(GRAPH_CSV_PATH, sep=\"|\", index=False)\n",
    "                    df.to_csv(CHUNKS_CSV_PATH, sep=\"|\", index=False)\n",
    "                    print(f\"  Extracted triples: {triples}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️ Could not parse JSON for '{node}'. Marking as seen.\")\n",
    "                    self.seen_nodes.add(node)\n",
    "                    continue\n",
    "\n",
    "                self.add_triples_to_graph(triples)\n",
    "                self.seen_nodes.add(node)\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        print(\n",
    "            f\"\\nDone! Graph has {self.graph.number_of_nodes()} nodes \"\n",
    "            f\"and {self.graph.number_of_edges()} edges.\"\n",
    "        )\n",
    "        net = Network(notebook=True, height=\"800px\", width=\"100%\")\n",
    "        net.from_nx(self.graph) \n",
    "        net.show_buttons(filter_=['physics'])\n",
    "        net.show(\"kg_visualization_8iter.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388c6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: data_output\\test_output1\n",
      "Output directory: data_output\\test_output1\n",
      "['chunks.csv', 'context_prox_df.csv', 'graph.csv']\n",
      "Output directory: data_output\\test_output1\n",
      "chunks.csv - Created on: 2025-07-27 20:51:56\n",
      "context_prox_df.csv - Created on: 2025-07-27 20:51:56\n",
      "graph.csv - Created on: 2025-07-27 20:51:56\n"
     ]
    }
   ],
   "source": [
    "out_dir = \"test_output1\"\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")\n",
    "print(f\"Output directory: {outputdirectory}\")\n",
    "#print the file and its creation time\n",
    "print(f\"Output directory: {outputdirectory}\")\n",
    "import os\n",
    "print(os.listdir(outputdirectory))\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Print the output directory\n",
    "print(f\"Output directory: {outputdirectory}\")\n",
    "\n",
    "# List files and print their creation times\n",
    "for filename in os.listdir(outputdirectory):\n",
    "    filepath = os.path.join(outputdirectory, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        creation_time = os.path.getctime(filepath)\n",
    "        readable_time = datetime.datetime.fromtimestamp(creation_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"{filename} - Created on: {readable_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2c529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc79fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_KG(text_files):\n",
    "    ## Dir PDF Loader example / adapt as needed\n",
    "    # loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "    # loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
    "\n",
    "    # loader = DirectoryLoader(inputdirectory, show_progress=True)       # Load all text files in directory\n",
    "    # documents = loader.load()\n",
    "\n",
    "    out_dir = \"test_output1\"\n",
    "    outputdirectory = Path(f\"./data_output/{out_dir}\")\n",
    "    print(f\"Output directory: {outputdirectory}\")\n",
    "    if not os.path.exists(outputdirectory):\n",
    "        os.makedirs(outputdirectory)\n",
    "    text_files = [f.split(\"/\")[-1] for f in text_files if f.endswith('.txt')]\n",
    "    text_loader = TextLoader(f\"{text_files[0]}\")      # Assumedly, load just one text file in the directory\n",
    "    text_lines = text_loader.load()\n",
    "\n",
    "    # Split the text by the newline character\n",
    "    print(text_lines)\n",
    "    text_chunks = text_lines\n",
    "    #text_chunks = text_lines.split('\\n')\n",
    "    print(text_chunks)\n",
    "\n",
    "    # Convert text to dataframe\n",
    "    df = text2Dataframe(text_chunks)\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "\n",
    "    ## To Generate or Regenerate the Knowldge Graph with LLM \n",
    "    #\n",
    "    regenerate = True       # set this to 'False' for the Concatenation process\n",
    "    GRAPH_CSV_PATH = outputdirectory / \"graph.csv\"\n",
    "    # CHUNKS_CSV_PATH = outputdirectory / \"chunks.csv\"\n",
    "\n",
    "    if regenerate:      # I doubt we need regeneration\n",
    "        concepts_list = df2Graph(df, model='gpt-4.1-mini')\n",
    "        dfg1 = graph2Df(concepts_list)\n",
    "        if not os.path.exists(outputdirectory):\n",
    "            os.makedirs(outputdirectory)\n",
    "        \n",
    "        dfg1.to_csv(GRAPH_CSV_PATH, sep=\"|\", index=False)\n",
    "        df.to_csv(CHUNKS_CSV_PATH, sep=\"|\", index=False)\n",
    "    else:\n",
    "        dfg1 = pd.read_csv(GRAPH_CSV_PATH, sep=\"|\")\n",
    "\n",
    "    # --- Load Existing Graph or Initialize Empty ---\n",
    "\n",
    "    #if os.path.exists(GRAPH_CSV_PATH):\n",
    "    #    print(\"Loading existing graph...\")\n",
    "    #    df_graph_existing = pd.read_csv(GRAPH_CSV_PATH, sep=\"|\")\n",
    "    #    df_chunks_existing = pd.read_csv(CHUNKS_CSV_PATH, sep=\"|\")\n",
    "#\n",
    "    #elif os.path.exists(GRAPH_CSV_PATH):\n",
    "    #    with open(LOG_FILE, 'r') as f:\n",
    "    #        content = f.read()\n",
    "    #        if not content:\n",
    "    #            print(\"LOG_FILE is empty.\")\n",
    "    #        else:\n",
    "    #            df_graph = pd.read_csv(GRAPH_CSV_PATH, sep=\"|\")\n",
    "    #            dfg1 = pd.concat([df_graph, dfg1], ignore_index=True)   # Concatenation process / still need modification\n",
    "    #    \n",
    "    #else:\n",
    "    #    print(\"No existing graph found. Starting fresh.\")\n",
    "    #    df_graph_existing = pd.DataFrame(columns=['node_1', 'node_2', 'edge', 'chunk_id'])\n",
    "    #    df_chunks_existing = pd.DataFrame(columns=['text', 'source', 'chunk_id'])\n",
    "\n",
    "        if os.path.exists(GRAPH_CSV_PATH):\n",
    "            print(\"Loading existing graph...\")\n",
    "            # df_chunks_existing = pd.read_csv(CHUNKS_CSV_PATH, sep=\"|\")\n",
    "\n",
    "            with open(LOG_FILE, 'r') as f:\n",
    "                content = f.read()\n",
    "                if not content:\n",
    "                    print(\"LOG_FILE is empty.\")\n",
    "                else:\n",
    "                    df_graph_existing = pd.read_csv(GRAPH_CSV_PATH, sep=\"|\")     # Reading the existing graph\n",
    "                    dfg1 = pd.concat([df_graph_existing, dfg1], ignore_index=True)   # Concatenation process / still need modification - esp. the text-chunking process  \n",
    "                    \n",
    "                    dfg1.replace(\"\", np.nan, inplace=True)\n",
    "                    dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "                    # Still confused about including 'count' column in this new implementation \n",
    "\n",
    "\n",
    "    ## Perform Contextual Proximity calculation / Use only if needed\n",
    "    #\n",
    "    dfg2 = contextual_proximity(dfg1)\n",
    "    dfg2.tail()\n",
    "    dfg2.to_csv(outputdirectory/\"context_prox_df.csv\", index=False)\n",
    "\n",
    "    ## Graph Concatenation & Aggregation\n",
    "    #\n",
    "    dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "    dfg = (\n",
    "        dfg.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    ## Graph-visualizier-building\n",
    "    \n",
    "    graph_viz_builder(dfg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd575cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_input\\\\final.txt']\n",
      "Output directory: data_output\\test_output1\n",
      "[Document(metadata={'source': 'data_input\\\\final.txt'}, page_content=\"Water and Earth gives me Mud\\nMud and Water gives me Swamp\\nMud and Earth gives me Clay\\nSwamp and Earth gives me Bog\\nSwamp and Water gives me Quagmire\\n\\nClay and Water gives me Sludge\\nFire and Water gives me Steam\\n\\nSteam and Water gives me Cloud\\n\\nSteam and Fire gives me Energy\\n\\nCloud and Fire gives me Thundercloud\\n\\nCloud and Water gives me Mist\\n\\nEnergy and Water gives me Boil\\n\\nEnergy and Fire gives me Plasma\\nWater and Air gives me Mist\\n\\nMist and Water gives me Dew\\n\\nMist and Air gives me Vapor\\n\\nDew and Water gives me Humidity\\n\\nDew and Air gives me Fog\\nFire and Water gives me Steam  \\nSteam and Earth gives me Geothermal Vapor  \\nSteam and Water gives me Condensed Mist\\nEarth and Fire gives me Lava\\n\\nLava and Earth gives me Obsidian\\n\\nLava and Fire gives me Plasma\\n\\nObsidian and Earth gives me Geode\\n\\nObsidian and Fire gives me Charcoal\\n\\nPlasma and Earth gives me Geothermal Essence\\n\\nPlasma and Fire gives me Stellar Flame\\nearth and air gives me Dust\\n\\nDust and earth gives me Clay\\n\\nDust and air gives me Mist\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Earth gives me Lava\\n\\nLava and Fire gives me Magma\\n\\nLava and Earth gives me Obsidian\\nFire and Air gives me **Ignisphere**\\n\\nIgnisphere and Fire gives me **Blazewhirl**\\n\\nIgnisphere and Air gives me **Sparkveil**\\nAir and Water gives me Mist\\n\\nMist and Air gives me Vapor\\nMist and Water gives me Dew\\nAir and Earth gives me Dust  \\nDust and Air gives me Mist  \\nDust and Earth gives me Clay\\nAir and Fire gives me **Zephyrium**  \\nZephyrium and Air gives me **Stratosphere**  \\nZephyrium and Fire gives me **Infernium**  \\nStratosphere and Fire gives me **Cumulonimbus**\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nwater_and_earth and earth gives me Mud\\n\\nmud and water_and_earth gives me Clay\\n\\nmud and earth gives me Loam\\n\\nmud and water_and_earth gives me Silt\\n\\nearth and water_and_earth gives me Soil\\nWater and Earth gives me Mud\\n\\nMud and Fire gives me Brick\\n\\nWater and Brick gives me Ceramic\\n\\nEarth and Brick gives me Terracotta\\n\\nFire and Terracotta gives me Glazed Pottery\\n\\nWater and Glazed Pottery gives me Enamelware\\n\\nEarth and Enamelware gives me Mineralized Ceramics\\nWater and Earth gives me Mud\\n\\nMud and Air gives me Dust\\n\\nWater and Air gives me Fog\\n\\nEarth and Air gives me Dust\\n\\nMud and Air gives me Clay\\n\\nDust and Water gives me Silt\\n\\nDust and Earth gives me Loam\\nMud and Water gives me Clay\\n\\nClay and Mud gives me Ceramic\\n\\nClay and Water gives me Loam\\n\\n---\\n\\nNote: Each new element is derived by combining the properties of the previous results with the original base elements. For instance, clay is a hardened, workable form of mud and water, leading to ceramic (a crafted, durable material). Loam is a fertile soil, blending mud and water qualities for growth.\\nMud and Earth gives me Clay\\n\\nClay and Mud gives me Ceramic  \\nClay and Earth gives me Sediment\\nMud and Fire gives me Molten Clay\\n\\nMolten Clay and Mud gives me Hardened Lava\\n\\nMolten Clay and Fire gives me Glazed Earthen Stone\\n\\nHardened Lava and Mud gives me Obsidian Mud\\n\\nHardened Lava and Fire gives me Crystallized Lava\\nMud and Air gives me Dust\\n\\nDust and Mud gives me Clay\\n\\nDust and Air gives me Particulate\\n\\nClay and Air gives me Ceramic\\n\\nClay and Mud gives me Terracotta\\n\\nParticulate and Mud gives me Loam\\n\\nParticulate and Air gives me Aerosol\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nMud_and_water and Earth gives me Clay  \\nClay and Mud_and_water gives me Silt  \\nClay and Earth gives me Soil  \\nSilt and Mud_and_water gives me Loam  \\nSilt and Earth gives me Topsoil\\nFire and Mud_and_Water gives me Steam-Infused Clay  \\nMud_and_Water and Fire gives me Vapor Mud  \\nFire and Vapor_Mud gives me Charred Vapor  \\nMud_and_Water and Vapor_Mud gives me Silted Mist\\nMud_and_water and air gives me Dampness  \\nDampness and mud_and_water gives me Sogginess  \\nDampness and air gives me Mist  \\nSogginess and air gives me Humidity\\nSwamp and Water gives me Marshland\\n\\nMarshland and Swamp gives me Fenlands\\n\\nMarshland and Water gives me Quagmire\\nSwamp and Earth gives me Marshland\\n\\nMarshland and Swamp gives me Quagmire\\n\\nMarshland and Earth gives me Fertile Ground\\nSwamp and Fire gives me **Lava**  \\nLava and Swamp gives me **Magma**  \\nLava and Fire gives me **Pyrolith**\\nSwamp and Air gives me Miasma\\nMud_and_earth and water gives me Clay  \\nClay and mud_and_earth gives me Ceramic  \\nClay and water gives me Muddy Water\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Mud_and_earth gives me Lava\\n\\nLava and Mud_and_earth gives me Magma\\n\\nLava and Fire gives me Obsidian\\n\\nMagma and Fire gives me Glass\\n\\nObsidian and Mud_and_earth gives me Volcanic Glass\\n\\nObsidian and Fire gives me Pyroclast\\n\\nGlass and Mud_and_earth gives me Terraglass\\n\\nPyroclast and Mud_and_earth gives me Ashstone\\nFire and Water gives me Steam\\nSteam and Fire gives me Energy\\nSteam and Water gives me Cloud\\nClay and Water gives me Mud\\n\\nMud and Clay gives me Silt\\n\\nMud and Water gives me Slimestone\\n\\nSilt and Water gives me Sediment\\n\\nSilt and Clay gives me Loam\\n\\nSediment and Clay gives me Claystone\\n\\nSediment and Water gives me Alluvium\\nClay and Earth gives me TerraMud\\n\\nTerraMud and Clay gives me CompactClay\\n\\nTerraMud and Earth gives me RichSoil\\nClay and Fire gives me FusedClay\\n\\nFusedClay and Clay gives me HardenedFusedClay\\n\\nFusedClay and Fire gives me MoltenClay\\nClay and Air gives me Earthen Breeze\\n\\nEarthen Breeze and Clay gives me Mudwhisper\\n\\nEarthen Breeze and Air gives me Skyclay\\n\\nMudwhisper and Clay gives me Siltveil\\n\\nMudwhisper and Air gives me Dustglide\\nSwamp_and_earth and water gives me Marshland Essence\\n\\nMarshland Essence and swamp_and_earth gives me Bog Spirit\\n\\nMarshland Essence and water gives me Mudflow\\n\\nBog Spirit and water gives me Poisonous Mire\\n\\nMudflow and swamp_and_earth gives me Sediment Core\\nSwamp_and_earth and earth gives me Marshland Essence\\nSwamp_and_earth and fire gives me Marshfire\\n\\nMarshfire and swamp_and_earth gives me Quagmireflame  \\nMarshfire and fire gives me Emberstorm\\nSwamp_and_earth and air gives me Marshland Essence\\n\\nMarshland Essence and swamp_and_earth gives me Peat Soil\\n\\nMarshland Essence and air gives me Misty Vapors\\nBog and Water gives me Mud\\n\\nMud and Bog gives me Silt\\n\\nMud and Water gives me Swamp\\n\\nSilt and Bog gives me Rich Sediment\\n\\nSilt and Water gives me Silty Stream\\n\\nRich Sediment and Bog gives me Fertile Deposit\\n\\nRich Sediment and Water gives me Nutrient-Rich Soil\\nBog and Earth gives me Mire\\n\\nMire and Bog gives me Quagmire\\n\\nMire and Earth gives me Clay\\n\\nQuagmire and Bog gives me Marshland\\n\\nQuagmire and Earth gives me Swampland\\nBog and Fire gives me Mudfire\\nBog and Air gives me Mist\\n\\nMist and Bog gives me Swamp Vapor\\n\\nMist and Air gives me Light Breeze\\n\\nSwamp Vapor and Bog gives me Marsh Gas\\n\\nSwamp Vapor and Air gives me Ethereal Fog\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nSwamp and Water gives me Marshfluid\\n\\nMarshfluid and Earth gives me Bogstone\\n\\nMarshfluid and Swamp gives me Quagmire Essence\\n\\nBogstone and Swamp gives me Mudcore\\n\\nQuagmire Essence and Earth gives me Swamp Heart\\nSwamp_and_water and fire gives me Bogfire\\n\\nBogfire and swamp_and_water gives me Marshblaze\\n\\nBogfire and fire gives me Emberstorm\\nSwamp_and_water and air gives me Misty Marsh\\n\\nMisty Marsh and swamp_and_water gives me Saturated Bog\\n\\nMisty Marsh and air gives me Vapor Veil\\nFire and Water gives me Steam  \\nSteam and Quagmire gives me Murkflow  \\nMurkflow and Water gives me Swampmelt\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Quagmire gives me Ashen Mire\\n\\nAshen Mire and Quagmire gives me Murky Ember\\n\\nAshen Mire and Fire gives me Lava Veil\\nQuagmire and Air gives me Mistral Mist\\n\\nMistral Mist and Quagmire gives me Eroded Veil\\n\\nMistral Mist and Air gives me Vaporveil\\nClay and Water gives me Mudsand\\n\\nMudsand and Water gives me Siltstone\\n\\nSiltstone and Clay gives me Earthenware\\n\\nEarthenware and Water gives me Porcelain\\n\\nPorcelain and Clay gives me Finechina\\n\\nFinechina and Water gives me Porcelite\\n\\n---\\n\\nPlease provide your specific input elements if you'd like me to continue generating more elements!\\nClay_and_water and earth gives me Mud\\n\\nMud and clay_and_water gives me Silt\\n\\nMud and earth gives me Loam\\n\\nSilt and earth gives me Fertile_soil\\n\\nLoam and water gives me Quagmire\\nClay_and_water and fire gives me Molten Clay  \\nMolten Clay and clay_and_water gives me Semi-Solid Clay  \\nMolten Clay and fire gives me Fired Molten Clay  \\nSemi-Solid Clay and fire gives me Burnt Clay\\nClay_and_water and air gives me Mist  \\nMist and clay_and_water gives me Muddy Mist  \\nMisty Mist and clay_and_water gives me Silt Cloud  \\nMist and air gives me Vapor  \\nMisty Mist and air gives me Hazy Vapor\\nSludge and Water gives me Muck\\n\\nMuck and Sludge gives me Viscid Ooze\\n\\nMuck and Water gives me Mudflow\\nSludge and Earth gives me Mire\\n\\nMire and Sludge gives me Thicket\\n\\nMire and Earth gives me Clay\\nFire and Sludge gives me Molten Ash\\n\\nMolten Ash and Sludge gives me Lava Residue\\n\\nMolten Ash and Fire gives me Incandescent Ember\\nSludge and Air gives me Muckair\\n\\nMuckair and Sludge gives me Mirecloud\\n\\nMuckair and Air gives me Gasquagmire\\n\")]\n",
      "[Document(metadata={'source': 'data_input\\\\final.txt'}, page_content=\"Water and Earth gives me Mud\\nMud and Water gives me Swamp\\nMud and Earth gives me Clay\\nSwamp and Earth gives me Bog\\nSwamp and Water gives me Quagmire\\n\\nClay and Water gives me Sludge\\nFire and Water gives me Steam\\n\\nSteam and Water gives me Cloud\\n\\nSteam and Fire gives me Energy\\n\\nCloud and Fire gives me Thundercloud\\n\\nCloud and Water gives me Mist\\n\\nEnergy and Water gives me Boil\\n\\nEnergy and Fire gives me Plasma\\nWater and Air gives me Mist\\n\\nMist and Water gives me Dew\\n\\nMist and Air gives me Vapor\\n\\nDew and Water gives me Humidity\\n\\nDew and Air gives me Fog\\nFire and Water gives me Steam  \\nSteam and Earth gives me Geothermal Vapor  \\nSteam and Water gives me Condensed Mist\\nEarth and Fire gives me Lava\\n\\nLava and Earth gives me Obsidian\\n\\nLava and Fire gives me Plasma\\n\\nObsidian and Earth gives me Geode\\n\\nObsidian and Fire gives me Charcoal\\n\\nPlasma and Earth gives me Geothermal Essence\\n\\nPlasma and Fire gives me Stellar Flame\\nearth and air gives me Dust\\n\\nDust and earth gives me Clay\\n\\nDust and air gives me Mist\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Earth gives me Lava\\n\\nLava and Fire gives me Magma\\n\\nLava and Earth gives me Obsidian\\nFire and Air gives me **Ignisphere**\\n\\nIgnisphere and Fire gives me **Blazewhirl**\\n\\nIgnisphere and Air gives me **Sparkveil**\\nAir and Water gives me Mist\\n\\nMist and Air gives me Vapor\\nMist and Water gives me Dew\\nAir and Earth gives me Dust  \\nDust and Air gives me Mist  \\nDust and Earth gives me Clay\\nAir and Fire gives me **Zephyrium**  \\nZephyrium and Air gives me **Stratosphere**  \\nZephyrium and Fire gives me **Infernium**  \\nStratosphere and Fire gives me **Cumulonimbus**\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nwater_and_earth and earth gives me Mud\\n\\nmud and water_and_earth gives me Clay\\n\\nmud and earth gives me Loam\\n\\nmud and water_and_earth gives me Silt\\n\\nearth and water_and_earth gives me Soil\\nWater and Earth gives me Mud\\n\\nMud and Fire gives me Brick\\n\\nWater and Brick gives me Ceramic\\n\\nEarth and Brick gives me Terracotta\\n\\nFire and Terracotta gives me Glazed Pottery\\n\\nWater and Glazed Pottery gives me Enamelware\\n\\nEarth and Enamelware gives me Mineralized Ceramics\\nWater and Earth gives me Mud\\n\\nMud and Air gives me Dust\\n\\nWater and Air gives me Fog\\n\\nEarth and Air gives me Dust\\n\\nMud and Air gives me Clay\\n\\nDust and Water gives me Silt\\n\\nDust and Earth gives me Loam\\nMud and Water gives me Clay\\n\\nClay and Mud gives me Ceramic\\n\\nClay and Water gives me Loam\\n\\n---\\n\\nNote: Each new element is derived by combining the properties of the previous results with the original base elements. For instance, clay is a hardened, workable form of mud and water, leading to ceramic (a crafted, durable material). Loam is a fertile soil, blending mud and water qualities for growth.\\nMud and Earth gives me Clay\\n\\nClay and Mud gives me Ceramic  \\nClay and Earth gives me Sediment\\nMud and Fire gives me Molten Clay\\n\\nMolten Clay and Mud gives me Hardened Lava\\n\\nMolten Clay and Fire gives me Glazed Earthen Stone\\n\\nHardened Lava and Mud gives me Obsidian Mud\\n\\nHardened Lava and Fire gives me Crystallized Lava\\nMud and Air gives me Dust\\n\\nDust and Mud gives me Clay\\n\\nDust and Air gives me Particulate\\n\\nClay and Air gives me Ceramic\\n\\nClay and Mud gives me Terracotta\\n\\nParticulate and Mud gives me Loam\\n\\nParticulate and Air gives me Aerosol\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nMud_and_water and Earth gives me Clay  \\nClay and Mud_and_water gives me Silt  \\nClay and Earth gives me Soil  \\nSilt and Mud_and_water gives me Loam  \\nSilt and Earth gives me Topsoil\\nFire and Mud_and_Water gives me Steam-Infused Clay  \\nMud_and_Water and Fire gives me Vapor Mud  \\nFire and Vapor_Mud gives me Charred Vapor  \\nMud_and_Water and Vapor_Mud gives me Silted Mist\\nMud_and_water and air gives me Dampness  \\nDampness and mud_and_water gives me Sogginess  \\nDampness and air gives me Mist  \\nSogginess and air gives me Humidity\\nSwamp and Water gives me Marshland\\n\\nMarshland and Swamp gives me Fenlands\\n\\nMarshland and Water gives me Quagmire\\nSwamp and Earth gives me Marshland\\n\\nMarshland and Swamp gives me Quagmire\\n\\nMarshland and Earth gives me Fertile Ground\\nSwamp and Fire gives me **Lava**  \\nLava and Swamp gives me **Magma**  \\nLava and Fire gives me **Pyrolith**\\nSwamp and Air gives me Miasma\\nMud_and_earth and water gives me Clay  \\nClay and mud_and_earth gives me Ceramic  \\nClay and water gives me Muddy Water\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Mud_and_earth gives me Lava\\n\\nLava and Mud_and_earth gives me Magma\\n\\nLava and Fire gives me Obsidian\\n\\nMagma and Fire gives me Glass\\n\\nObsidian and Mud_and_earth gives me Volcanic Glass\\n\\nObsidian and Fire gives me Pyroclast\\n\\nGlass and Mud_and_earth gives me Terraglass\\n\\nPyroclast and Mud_and_earth gives me Ashstone\\nFire and Water gives me Steam\\nSteam and Fire gives me Energy\\nSteam and Water gives me Cloud\\nClay and Water gives me Mud\\n\\nMud and Clay gives me Silt\\n\\nMud and Water gives me Slimestone\\n\\nSilt and Water gives me Sediment\\n\\nSilt and Clay gives me Loam\\n\\nSediment and Clay gives me Claystone\\n\\nSediment and Water gives me Alluvium\\nClay and Earth gives me TerraMud\\n\\nTerraMud and Clay gives me CompactClay\\n\\nTerraMud and Earth gives me RichSoil\\nClay and Fire gives me FusedClay\\n\\nFusedClay and Clay gives me HardenedFusedClay\\n\\nFusedClay and Fire gives me MoltenClay\\nClay and Air gives me Earthen Breeze\\n\\nEarthen Breeze and Clay gives me Mudwhisper\\n\\nEarthen Breeze and Air gives me Skyclay\\n\\nMudwhisper and Clay gives me Siltveil\\n\\nMudwhisper and Air gives me Dustglide\\nSwamp_and_earth and water gives me Marshland Essence\\n\\nMarshland Essence and swamp_and_earth gives me Bog Spirit\\n\\nMarshland Essence and water gives me Mudflow\\n\\nBog Spirit and water gives me Poisonous Mire\\n\\nMudflow and swamp_and_earth gives me Sediment Core\\nSwamp_and_earth and earth gives me Marshland Essence\\nSwamp_and_earth and fire gives me Marshfire\\n\\nMarshfire and swamp_and_earth gives me Quagmireflame  \\nMarshfire and fire gives me Emberstorm\\nSwamp_and_earth and air gives me Marshland Essence\\n\\nMarshland Essence and swamp_and_earth gives me Peat Soil\\n\\nMarshland Essence and air gives me Misty Vapors\\nBog and Water gives me Mud\\n\\nMud and Bog gives me Silt\\n\\nMud and Water gives me Swamp\\n\\nSilt and Bog gives me Rich Sediment\\n\\nSilt and Water gives me Silty Stream\\n\\nRich Sediment and Bog gives me Fertile Deposit\\n\\nRich Sediment and Water gives me Nutrient-Rich Soil\\nBog and Earth gives me Mire\\n\\nMire and Bog gives me Quagmire\\n\\nMire and Earth gives me Clay\\n\\nQuagmire and Bog gives me Marshland\\n\\nQuagmire and Earth gives me Swampland\\nBog and Fire gives me Mudfire\\nBog and Air gives me Mist\\n\\nMist and Bog gives me Swamp Vapor\\n\\nMist and Air gives me Light Breeze\\n\\nSwamp Vapor and Bog gives me Marsh Gas\\n\\nSwamp Vapor and Air gives me Ethereal Fog\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nSwamp and Water gives me Marshfluid\\n\\nMarshfluid and Earth gives me Bogstone\\n\\nMarshfluid and Swamp gives me Quagmire Essence\\n\\nBogstone and Swamp gives me Mudcore\\n\\nQuagmire Essence and Earth gives me Swamp Heart\\nSwamp_and_water and fire gives me Bogfire\\n\\nBogfire and swamp_and_water gives me Marshblaze\\n\\nBogfire and fire gives me Emberstorm\\nSwamp_and_water and air gives me Misty Marsh\\n\\nMisty Marsh and swamp_and_water gives me Saturated Bog\\n\\nMisty Marsh and air gives me Vapor Veil\\nFire and Water gives me Steam  \\nSteam and Quagmire gives me Murkflow  \\nMurkflow and Water gives me Swampmelt\\nFire and Water gives me Steam  \\nSteam and Fire gives me Energy  \\nSteam and Water gives me Cloud\\nFire and Quagmire gives me Ashen Mire\\n\\nAshen Mire and Quagmire gives me Murky Ember\\n\\nAshen Mire and Fire gives me Lava Veil\\nQuagmire and Air gives me Mistral Mist\\n\\nMistral Mist and Quagmire gives me Eroded Veil\\n\\nMistral Mist and Air gives me Vaporveil\\nClay and Water gives me Mudsand\\n\\nMudsand and Water gives me Siltstone\\n\\nSiltstone and Clay gives me Earthenware\\n\\nEarthenware and Water gives me Porcelain\\n\\nPorcelain and Clay gives me Finechina\\n\\nFinechina and Water gives me Porcelite\\n\\n---\\n\\nPlease provide your specific input elements if you'd like me to continue generating more elements!\\nClay_and_water and earth gives me Mud\\n\\nMud and clay_and_water gives me Silt\\n\\nMud and earth gives me Loam\\n\\nSilt and earth gives me Fertile_soil\\n\\nLoam and water gives me Quagmire\\nClay_and_water and fire gives me Molten Clay  \\nMolten Clay and clay_and_water gives me Semi-Solid Clay  \\nMolten Clay and fire gives me Fired Molten Clay  \\nSemi-Solid Clay and fire gives me Burnt Clay\\nClay_and_water and air gives me Mist  \\nMist and clay_and_water gives me Muddy Mist  \\nMisty Mist and clay_and_water gives me Silt Cloud  \\nMist and air gives me Vapor  \\nMisty Mist and air gives me Hazy Vapor\\nSludge and Water gives me Muck\\n\\nMuck and Sludge gives me Viscid Ooze\\n\\nMuck and Water gives me Mudflow\\nSludge and Earth gives me Mire\\n\\nMire and Sludge gives me Thicket\\n\\nMire and Earth gives me Clay\\nFire and Sludge gives me Molten Ash\\n\\nMolten Ash and Sludge gives me Lava Residue\\n\\nMolten Ash and Fire gives me Incandescent Ember\\nSludge and Air gives me Muckair\\n\\nMuckair and Sludge gives me Mirecloud\\n\\nMuckair and Air gives me Gasquagmire\\n\")]\n",
      "(1, 3)\n",
      "(131, 5)\n",
      "./docs/index_LA.html\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Not performing textsplit-and-overlapping chunking process as of now, \n",
    "        bcs the inputs to this modification are just independent lines of text separated by newline character (\\n). \n",
    "        Also, only one new text file at a time. \n",
    "    \"\"\"\n",
    "    import pathlib\n",
    "    first_run = True       # Change to 'False' after the first graph creation\n",
    "    INPUT_DIR = pathlib.Path('./data_input')\n",
    "    LOG_FILE = pathlib.Path(LOG_FILE)\n",
    "    if first_run:\n",
    "        if not os.listdir(INPUT_DIR):\n",
    "            print(\"Directory is empty\")\n",
    "        else:\n",
    "            text_files = [str(p) for p in INPUT_DIR.glob(\"**/*.txt\")]\n",
    "            print(text_files)\n",
    "            #text_files = \"\"\n",
    "            \n",
    "            # Processing files for the first time\n",
    "            if LOG_FILE.exists():\n",
    "                with open(LOG_FILE, 'r') as f:\n",
    "                    processed_files = set(f.read().splitlines())\n",
    "            else:\n",
    "                processed_files = set()     # Creating 'log file' if one not already created\n",
    "            \n",
    "            implement_KG(text_files)      # Generate/Concatenate Knowledge Graph\n",
    "\n",
    "            with open(LOG_FILE, 'a') as f:  # Logging new processed files\n",
    "                for file in text_files:\n",
    "                    f.write(file + '\\n')\n",
    "    else:\n",
    "        all_files = {str(p) for p in INPUT_DIR.glob(\"**/*.txt\")}\n",
    "        if LOG_FILE.exists():\n",
    "                with open(LOG_FILE, 'r') as f:\n",
    "                    processed_files = set(f.read().splitlines())\n",
    "\n",
    "        # Finding newly added files\n",
    "        new_files = list(all_files - processed_files)\n",
    "\n",
    "        if not new_files:\n",
    "            print(\"No new files to process.\")\n",
    "            # Optionally exit or continue as needed\n",
    "        else:\n",
    "            print(f\"Processing {len(new_files)} new files...\\n\")\n",
    "            implement_KG(new_files)        # Still need to modify this for improved Graph Concatenation\n",
    "\n",
    "            with open(LOG_FILE, 'a') as f:  # Logging new processed files\n",
    "                for file in all_files:\n",
    "                    f.write(file + '\\n')\n",
    "\n",
    "    print(\"\\nDone.\")\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-selection-agent (3.9.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
